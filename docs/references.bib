@article{DPR_2017,
  author = {Duvendack, Maren and Palmer-Jones, Richard and Reed, W.~Robert},
  title = {What Is Meant by Replication and Why Does It Encounter Resistance in Economics?},
  journal = {American Economic Review},
  volume = {107},
  number = {5},
  year = {2017},
  month = {May},
  pages = {46--51},
  doi = {10.1257/aer.p20171031}
}

@article{GL_2014,
  author = {Gelman, Andre and Loken, Eric},
  title = {The Statistical Crisis in Science},
  journal = {American Scientist},
  year = {2014},
  volume = {102},
  number = {6},
  pages = {460-465},
  doi = {10.1511/2014.111.460}
}

@article{GGR_2018,
  author = {Gertler, Paul and Galiani, Sebastian and Romero, Mauricio},
  title = {How to make replication the norm},
  journal = {Nature},
  volume = {554},
  year = {2018},
  month = {February},
  pages = {417--419},
  doi = {10.1038/d41586-018-02108-9}
}

@article{I_2005,
    author = {Ioannidis, John P. A.},
    journal = {PLOS Medicine},
    publisher = {Public Library of Science},
    title = {Why Most Published Research Findings Are False},
    year = {2005},
    month = {08},
    volume = {2},
    pages = {696-701},
    number = {8},
    doi = {10.1371/journal.pmed.0020124}
}

@article{SNS_2011,
  author = {Joseph P. Simmons and Leif D. Nelson and Uri Simonsohn},
  title ={False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant},
  journal = {Psychological Science},
  volume = {22},
  number = {11},
  pages = {1359-1366},
  year = {2011},
  doi = {10.1177/0956797611417632}
}

@book{CFM_2019,
  author = {Christensen, Garret, and Freese, Jeremy and Miguel, Edward},
  title = {Transparent and Reproducible Social Science Research: How to Do Open Science},
  year = {2019},
  publisher = {University of California Press}
}

@article{W_2017,
    author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
    journal = {PLOS Computational Biology},
    title = {Good enough practices in scientific computing},
    year = {2017},
    month = {06},
    volume = {13},
    number = {6},
    pages = {1-20},
    doi = {10.1371/journal.pcbi.1005510}
}

@Article{AJN_2023,
	author={Acciai, Claudia and Schneider, Jesper W. and Nielsen, Mathias W.},
	title={Estimating social bias in data sharing behaviours: an open science experiment},
	journal={Scientific Data},
	year={2023},
	month={Apr},
	day={21},
	volume={10},
	number={1},
	pages={233},
	abstract={Open data sharing is critical for scientific progress. Yet, many authors refrain from sharing scientific data, even when they have promised to do so. Through a preregistered, randomized audit experiment (N{\thinspace}={\thinspace}1,634), we tested possible ethnic, gender and status-related bias in scientists' data-sharing willingness. 814 (54{\%}) authors of papers where data were indicated to be `available upon request' responded to our data requests, and 226 (14{\%}) either shared or indicated willingness to share all or some data. While our preregistered hypotheses regarding bias in data-sharing willingness were not confirmed, we observed systematically lower response rates for data requests made by putatively Chinese treatments compared to putatively Anglo-Saxon treatments. Further analysis indicated a theoretically plausible heterogeneity in the causal effect of ethnicity on data-sharing. In interaction analyses, we found indications of lower responsiveness and data-sharing willingness towards male but not female data requestors with Chinese names. These disparities, which likely arise from stereotypic beliefs about male Chinese requestors' trustworthiness and deservingness, impede scientific progress by preventing the free circulation of knowledge.},
	issn={2052-4463},
	doi={10.1038/s41597-023-02129-8},
	url={https://doi.org/10.1038/s41597-023-02129-8}
}

@Article{FLCPSWMBP_2023,
	author={Ferguson, Joel 
and Littman, Rebecca
and Christensen, Garret
and Paluck, Elizabeth Levy
and Swanson, Nicholas
and Wang, Zenan
and Miguel, Edward
and Birke, David
and Pezzuto, John-Henry},
	title={Survey of open science practices and attitudes in the social sciences},
	journal={Nature Communications},
	year={2023},
	month={Sep},
	day={05},
	volume={14},
	number={1},
	pages={5401},
	abstract={Open science practices such as posting data or code and pre-registering analyses are increasingly prescribed and debated in the applied sciences, but the actual popularity and lifetime usage of these practices remain unknown. This study provides an assessment of attitudes toward, use of, and perceived norms regarding open science practices from a sample of authors published in top-10 (most-cited) journals and PhD students in top-20 ranked North American departments from four major social science disciplines: economics, political science, psychology, and sociology. We observe largely favorable private attitudes toward widespread lifetime usage (meaning that a researcher has used a particular practice at least once) of open science practices. As of 2020, nearly 90{\%} of scholars had ever used at least one such practice. Support for posting data or code online is higher (88{\%} overall support and nearly at the ceiling in some fields) than support for pre-registration (58{\%} overall). With respect to norms, there is evidence that the scholars in our sample appear to underestimate the use of open science practices in their field. We also document that the reported lifetime prevalence of open science practices increased from 49{\%} in 2010 to 87{\%} a decade later.},
	issn={2041-1723},
	doi={10.1038/s41467-023-41111-1},
	url={https://doi.org/10.1038/s41467-023-41111-1}
}

@article{GFI_2016,
title = "What does research reproducibility mean?",
abstract = "The language and conceptual framework of {"}research reproducibility{"} are nonstandard and unsettled across the sciences. In this Perspective, we review an array of explicit and implicit definitions of reproducibility and related terminology, and discuss how to avoid potential misunderstandings when these terms are used as a surrogate for {"}truth{"}.",
author = "Goodman, {Steven N.} and Daniele Fanelli and Ioannidis, {John P A}",
year = "2016",
month = jun,
day = "1",
doi = "10.1126/scitranslmed.aaf5027",
language = "English (US)",
volume = "8",
journal = "Science Translational Medicine",
issn = "1946-6234",
publisher = "American Association for the Advancement of Science",
number = "341",
}

@article{NSF_2015,
	title="Social, Behavioral, and Economic Sciences Perspectives on Robust and Reliable Science",
	author="Bollen, Kenneth  and Cacioppo, John T. and Kaplan, Robert M. and Krosnick, Jon A. and Olds, James L.",
	url="https://www.nsf.gov/sbe/AC_Materials/SBE_Robust_and_Reliable_Research_Report.pdf",
	organization="National Science Foundation",
	year="2015",
}

@Article{M_2017,
author={Munaf{\`o}, Marcus R.
and Nosek, Brian A.
and Bishop, Dorothy V. M.
and Button, Katherine S.
and Chambers, Christopher D.
and Percie du Sert, Nathalie
and Simonsohn, Uri
and Wagenmakers, Eric-Jan
and Ware, Jennifer J.
and Ioannidis, John P. A.},
title={A manifesto for reproducible science},
journal={Nature Human Behaviour},
year={2017},
month={Jan},
day={10},
volume={1},
number={1},
pages={0021},
abstract={Improving the reliability and efficiency of scientific research will increase the credibility of the published scientific literature and accelerate discovery. Here we argue for the adoption of measures to optimize key elements of the scientific process: methods, reporting and dissemination, reproducibility, evaluation and incentives. There is some evidence from both simulations and empirical studies supporting the likely effectiveness of these measures, but their broad adoption by researchers, institutions, funders and journals will require iterative evaluation and improvement. We discuss the goals of these measures, and how they can be implemented, in the hope that this will facilitate action toward improving the transparency, reproducibility and efficiency of scientific research.},
issn={2397-3374},
doi={10.1038/s41562-016-0021},
url={https://doi.org/10.1038/s41562-016-0021}
}

@article{HLL_2020,
author = {Hail, Luzi and Lang, Mark and Leuz, Christian},
title = {Reproducibility in Accounting Research: Views of the Research Community},
journal = {Journal of Accounting Research},
volume = {58},
number = {2},
pages = {519-543},
keywords = {accounting research, ethics, expert survey, publication process, research methodology, replication, reproducibility},
doi = {10.1111/1475-679X.12305},
abstract = {We have little knowledge about the prevalence of irreproducibility in the accounting literature. To narrow this gap, we conducted a survey among the participants of the 2019 JAR Conference on their perceptions of the frequency, causes, and consequences of irreproducible research published in accounting journals. A majority of respondents believe that irreproducibility is common in the literature, constitutes a major problem, and receives too little attention. Most have encountered irreproducibility in the work of others (although not in their own work) but chose not to pursue their failed reproduction attempts to publication. Respondents believe irreproducibility results chiefly from career or publication incentives as well as from selective reporting of results. They also believe that practices like sharing code and data combined with stronger incentives to replicate the work of others would enhance reproducibility. The views of accounting researchers are remarkably similar to those expressed in a survey by the scientific journal Nature. We conclude by discussing the implications of our findings and provide several potential paths forward for the accounting research community.},
year = {2020}
}

@article{G_2023,
url = {https://doi.org/10.1515/ael-2022-0111},
title = {The Elephant in the Room: p-hacking and Accounting Research},
author = {Ian D. Gow},
journal = {Accounting, Economics, and Law: A Convivium},
doi = {10.1515/ael-2022-0111},
year = {2023},
lastchecked = {2024-02-13}
}

@article{S_2023,
title = {To replicate or not to replicate? That is the question},
journal = {Journal of Accounting and Public Policy},
volume = {42},
number = {6},
pages = {107151},
year = {2023},
issn = {0278-4254},
doi = {10.1016/j.jaccpubpol.2023.107151},
url = {https://www.sciencedirect.com/science/article/pii/S0278425423001114},
author = {Divesh S. Sharma},
keywords = {Credible, Method, Publication bias, Reliable, Replicate, Replication crisis},
abstract = {The scientific research world was shaken by revelations of a crisis in reproducing well-regarded research in psychology. This crisis reverberated across several academic disciplines including accounting, which led to controversy about the place and status of replications in accounting. The imperative for encouraging replications in our field is not new and has been met largely with opposition. While antagonists and advocates hold their ground, I believe it is critical to address misconceptions of the role and value of replication studies. In this essay, I clarify the role of replications focusing on two general types of replication: close and differentiated replications. I then discuss the status of replication in accounting followed by a brief narrative on a well-known replication in the auditor independence literature. My concluding comments weave through suggested pathways for a better understanding of replication studies.}
}

@article{CGL_2024,
	title="Discontinuous Distribution of Test Statistics Around Significance Thresholds in Empirical Accounting Studies",
	author="Chang, Xin and Gao, Huasheng and Li, Wei",
	journal = {Journal of Accounting Research},
	volume = {(forthcoming)},
	number = {},
	pages = {},
	year={2024}, 
	url = {https://doi.org/10.1111/1475-679X.12579}
}

@article{CSW_2016,
  title={oTree—An open-source platform for laboratory, online, and field experiments},
  author={Chen, Daniel L and Schonger, Martin and Wickens, Chris},
  journal={Journal of Behavioral and Experimental Finance},
  volume={9},
  pages={88--97},
  year={2016},
  publisher={Elsevier},
  doi="10.1016/j.jbef.2015.12.001",
}

@article{B_2016,
  title={Reproducibility crisis},
  author={Baker, Monya},
  journal={Nature},
  volume={533},
  number={26},
  pages={353--66},
  year={2016},
  url="https://www.nature.com/articles/533452a"
}

@article{CDF_2016,
  title={Evaluating replicability of laboratory experiments in economics},
  author={Camerer, Colin F and Dreber, Anna and Forsell, Eskil and Ho, Teck-Hua and Huber, J{\"u}rgen and Johannesson, Magnus and Kirchler, Michael and Almenberg, Johan and Altmejd, Adam and Chan, Taizan and others},
  journal={Science},
  volume={351},
  number={6280},
  pages={1433--1436},
  year={2016},
  publisher={American Association for the Advancement of Science},
  doi="doi.org/10.1126/science.aaf0918",
}

@article{OSC_2015,
  title={Estimating the reproducibility of psychological science},
  author={Open Science Collaboration, },
  journal={Science},
  volume={349},
  number={6251},
  pages={aac4716},
  year={2015},
  publisher={American Association for the Advancement of Science},
  doi="10.1126/science.aac4716",
}

@article{LSA_2024,
    author = {Luo, Yi and Salterio, Steven E. and Adamson, Constance},
    title = "{Replication of Audit and Financial Accounting Research: We Do More than We Think}",
    journal = {Accounting Horizons},
    pages = {1-17},
    year = {2024},
    month = {01},
    abstract = "{There is a widespread concern that a “replication crisis” exists in the social sciences. Accounting researchers echo this claim and add that little accounting replication research is published. We carry out a conservative study to identify articles published in six leading accounting journals from 1970 to 2016 that attempt to replicate prior financial accounting and auditing research. We find 248 articles that attempted to replicate, in whole or in part, 298 published papers’ results typically in the context of extending the original finds. Highlights of our findings include: (1) the number and percentage of replicating articles have increased over the period; (2) 60 percent of all replication attempts are completely successful, 29 percent report mixed success, leaving 11 percent that fail to replicate. These findings suggest that the accounting academe publishes more replication research than previously documented and that published results are relatively robust when replicated.Data Availability: Data are available from the authors upon request.}",
    issn = {0888-7993},
    doi = {10.2308/HORIZONS-2022-152},
    url = {https://doi.org/10.2308/HORIZONS-2022-152},
    eprint = {https://publications.aaahq.org/accounting-horizons/article-pdf/doi/10.2308/HORIZONS-2022-152/103938/horizons-2022-152.pdf},
}

@article{FGHKO_2023,
author = {Fi\v{s}ar, Milo\v{s} and Greiner, Ben and Huber, Christoph and Katok, Elena and Ozkes, Ali I. and },
title = {Reproducibility in Management Science},
journal = {Management Science},
year = {2023},
doi = {10.1287/mnsc.2023.03556},
URL = {https://doi.org/10.1287/mnsc.2023.03556},
abstract = { With the help of more than 700 reviewers, we assess the reproducibility of nearly 500 articles published in the journal Management Science before and after the introduction of a new Data and Code Disclosure policy in 2019. When considering only articles for which data accessibility and hardware and software requirements were not an obstacle for reviewers, the results of more than 95\% of articles under the new disclosure policy could be fully or largely computationally reproduced. However, for 29\% of articles, at least part of the data set was not accessible to the reviewer. Considering all articles in our sample reduces the share of reproduced articles to 68\%. These figures represent a significant increase compared with the period before the introduction of the disclosure policy, where only 12\% of articles voluntarily provided replication materials, of which 55\% could be (largely) reproduced. Substantial heterogeneity in reproducibility rates across different fields is mainly driven by differences in data set accessibility. Other reasons for unsuccessful reproduction attempts include missing code, unresolvable code errors, weak or missing documentation, and software and hardware requirements and code complexity. Our findings highlight the importance of journal code and data disclosure policies and suggest potential avenues for enhancing their effectiveness.This paper was accepted by David Simchi-Levi, behavioral economics and decision analysis–fast track.Supplemental Material: The online appendices and data are available at https://doi.org/10.1287/mnsc.2023.03556. }
}

@article{G_2022,
author = {Gomes, Dylan G. E.  and Pottier, Patrice  and Crystal-Ornelas, Robert  and Hudgins, Emma J.  and Foroughirad, Vivienne  and Sánchez-Reyes, Luna L.  and Turba, Rachel  and Martinez, Paula Andrea  and Moreau, David  and Bertram, Michael G.  and Smout, Cooper A.  and Gaynor, Kaitlyn M. },
title = {Why don't we share data and code? Perceived barriers and benefits to public archiving practices},
journal = {Proceedings of the Royal Society B: Biological Sciences},
volume = {289},
number = {1987},
pages = {20221113},
year = {2022},
doi = {10.1098/rspb.2022.1113},
URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rspb.2022.1113},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rspb.2022.1113},
abstract = { The biological sciences community is increasingly recognizing the value of open, reproducible and transparent research practices for science and society at large. Despite this recognition, many researchers fail to share their data and code publicly. This pattern may arise from knowledge barriers about how to archive data and code, concerns about its reuse, and misaligned career incentives. Here, we define, categorize and discuss barriers to data and code sharing that are relevant to many research fields. We explore how real and perceived barriers might be overcome or reframed in the light of the benefits relative to costs. By elucidating these barriers and the contexts in which they arise, we can take steps to mitigate them and align our actions with the goals of open science, both as individual scientists and as a scientific community. }
}

@article{PDF_2007,
    doi = {10.1371/journal.pone.0000308},
    author = {Piwowar, Heather A. and Day, Roger S. and Fridsma, Douglas B.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Sharing Detailed Research Data Is Associated with Increased Citation Rate},
    year = {2007},
    month = {03},
    volume = {2},
    pages = {1-5},
    abstract = {BackgroundSharing research data provides benefit to the general scientific community, but the benefit is less obvious for the investigator who makes his or her data available.Principal FindingsWe examined the citation history of 85 cancer microarray clinical trial publications with respect to the availability of their data. The 48% of trials with publicly available microarray data received 85% of the aggregate citations. Publicly available data was significantly (p = 0.006) associated with a 69% increase in citations, independently of journal impact factor, date of publication, and author country of origin using linear regression.SignificanceThis correlation between publicly available data and increased literature impact may further motivate investigators to share their detailed research data.},
    number = {3}
}

@article{LM_2011,
author = {Loughran, Tim and Mcdonald, Bill},
title = {When Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10-Ks},
journal = {The Journal of Finance},
volume = {66},
number = {1},
pages = {35-65},
doi = {10.1111/j.1540-6261.2010.01625.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.2010.01625.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-6261.2010.01625.x},
abstract = {ABSTRACT Previous research uses negative word counts to measure the tone of a text. We show that word lists developed for other disciplines misclassify common words in financial text. In a large sample of 10-Ks during 1994 to 2008, almost three-fourths of the words identified as negative by the widely used Harvard Dictionary are words typically not considered negative in financial contexts. We develop an alternative negative word list, along with five other word lists, that better reflect tone in financial text. We link the word lists to 10-K filing returns, trading volume, return volatility, fraud, material weakness, and unexpected earnings.},
year = {2011}
}

@article{H_2019,
    author = {Hassan, Tarek A and Hollander, Stephan and van Lent, Laurence and Tahoun, Ahmed},
    title = "{Firm-Level Political Risk: Measurement and Effects*}",
    journal = {The Quarterly Journal of Economics},
    volume = {134},
    number = {4},
    pages = {2135-2202},
    year = {2019},
    month = {08},
    abstract = "{We adapt simple tools from computational linguistics to construct a new measure of political risk faced by individual U.S. firms: the share of their quarterly earnings conference calls that they devote to political risks. We validate our measure by showing that it correctly identifies calls containing extensive conversations on risks that are political in nature, that it varies intuitively over time and across sectors, and that it correlates with the firm’s actions and stock market volatility in a manner that is highly indicative of political risk. Firms exposed to political risk retrench hiring and investment and actively lobby and donate to politicians. These results continue to hold after controlling for news about the mean (as opposed to the variance) of political shocks. Interestingly, the vast majority of the variation in our measure is at the firm level rather than at the aggregate or sector level, in the sense that it is captured neither by the interaction of sector and time fixed effects nor by heterogeneous exposure of individual firms to aggregate political risk. The dispersion of this firm-level political risk increases significantly at times with high aggregate political risk. Decomposing our measure of political risk by topic, we find that firms that devote more time to discussing risks associated with a given political topic tend to increase lobbying on that topic, but not on other topics, in the following quarter.}",
    issn = {0033-5533},
    doi = {10.1093/qje/qjz021},
    url = {https://doi.org/10.1093/qje/qjz021},
    eprint = {https://academic.oup.com/qje/article-pdf/134/4/2135/32666210/qjz021.pdf},
}


@article{HP_2016,
author = {Hoberg, Gerard and Phillips, Gordon},
title = {Text-Based Network Industries and Endogenous Product Differentiation},
journal = {Journal of Political Economy},
volume = {124},
number = {5},
pages = {1423-1465},
year = {2016},
doi = {10.1086/688176},
URL = {https://doi.org/10.1086/688176},
abstract = { We study how firms differ from their competitors using new time-varying measures of product similarity based on text-based analysis of firm 10-K product descriptions. This year-by-year set of product similarity measures allows us to generate a new set of industries in which firms can have their own distinct set of competitors. Our new sets of competitors explain specific discussion of high competition, rivals identified by managers as peer firms, and changes to industry competitors following exogenous industry shocks. We also find evidence that firm R\&D and advertising are associated with subsequent differentiation from competitors, consistent with theories of endogenous product differentiation. }
}

@article{BBB_2024,
	author = {Boulland, Romain and Bourveau, Thomas and Breuer, Matthias},
	title = {Corporate Websites: A New Measure of Disclosure},
	journal = {Journal of Accounting Research},
	volume = {(forthcoming)},
	year = {2024},
	doi = {10.2139/ssrn.3816623}
}

@article{M_2014, 
	author={Moravcsik, Andrew}, 
	title={Transparency: The Revolution in Qualitative Research}, 
	volume={47}, 
	DOI={10.1017/S1049096513001789}, 
	number={1}, journal={PS: Political Science & Politics}, 
	year={2014}, 
	pages={48–53}
} 

@article{FRV_2022,
title = {Advances in transparency and reproducibility in the social sciences},
journal = {Social Science Research},
volume = {107},
pages = {102770},
year = {2022},
issn = {0049-089X},
doi = {10.1016/j.ssresearch.2022.102770},
url = {https://www.sciencedirect.com/science/article/pii/S0049089X2200076X},
author = {Jeremy Freese and Tamkinat Rauf and Jan Gerrit Voelkel},
keywords = {Open science, Reproducibility, Transparency},
abstract = {Worries about a “credibility crisis” besieging science have ignited interest in research transparency and reproducibility as ways of restoring trust in published research. For quantitative social science, advances in transparency and reproducibility can be seen as a set of developments whose trajectory predates the recent alarm. We discuss several of these developments, including preregistration, data-sharing, formal infrastructure in the form of resources and policies, open access to research, and specificity regarding research contributions. We also discuss the spillovers of this predominantly quantitative effort towards transparency for qualitative research. We conclude by emphasizing the importance of mutual accountability for effective science, the essential role of openness for this accountability, and the importance of scholarly inclusiveness in figuring out the best ways for openness to be accomplished in practice.}
}

@article{SW_2023, 
	author={Summers, Scott L. and Wood, David A.}, 
	title={Accounting Research Ranking}, 
	year={2023}, 
	url={http://www.byuaccounting.net/rankings}
} 

@article{AM_2019,
  title={Open science challenges, benefits and tips in early career and beyond},
  author={Allen, Christopher and Mehler, David MA},
  journal={PLoS Biology},
  volume={17},
  number={5},
  pages={e3000246},
  year={2019},
  publisher={Public Library of Science San Francisco, CA USA},
  url = {https://doi.org/10.1371/journal.pbio.3000587}
}

@article{ABC_2021,
  title={Towards wide-scale adoption of open science practices: The role of open science communities},
  author={Armeni, Kristijan and Brinkman, Loek and Carlsson, Rickard and Eerland, Anita and Fijten, Rianne and Fondberg, Robin and Heininga, Vera E and Heunis, Stephan and Koh, Wei Qi and Masselink, Maurits and others},
  journal={Science and Public Policy},
  volume={48},
  number={5},
  pages={605-611},
  year={2021},
  url = {https://doi.org/10.1093/scipol/scab039}
}

@article{M_1981,
  title={Good news and bad news: Representation theorems and applications},
  author={Milgrom, Paul R},
  journal={The Bell Journal of Economics},
  volume={12},
  number={2},  
  pages={380-391},
  year={1981},
  url={https://doi.org/10.2307/3003562}
}

@article{BCLW_2010,
	title={The financial reporting environment: Review of the recent literature},
	author={Beyer, Anne and Cohen, Daniel and Lys, Thomas, and Walther, Beverly},
	journal={Journal of Accounting and Economics},
	volume={50},
	number={2-3},
	pages={296-343},
	year={2010},
	url={https://doi.org/10.1016/j.jacceco.2010.10.003}
}

@article{S_1980,
	title={The Pricing of Audit Services: Theory and Evidence},
	author={Simunic, Dan},
	journal={Journal of Accounting Research},
	volume={18},
	number={1},
	pages={161-190},
	year={1980},
	url={https://doi.org/10.2307/2490397}
}


@article{V_1983,
  title={Discretionary disclosure},
  author={Verrecchia, Robert E},
  journal={Journal of Accounting and Economics},
  volume={5},
  pages={179-194},
  year={1983},
  url={https://doi.org/10.1016/0165-4101(83)90011-3}
}

@article{LT_2005,
	journal = {Journal of Economic Perspectives},
	author = {Lerner, Josh and Tirole, Jean},
	title = {The Economics of Technology Sharing: Open Source and Beyond},
	volume = {19},
	number = {2},
	year = {2005},
	pages = {99–120},
	url = {https://doi.org/10.1257/0895330054048678}
}

@article{MS_2019,
	title = {Disclosure or secrecy? The dynamics of Open Science},
	author = {Arijit Mukherjee and Scott Stern},
	journal = {International Journal of Industrial Organization},
	volume = {27},
	number = {3},
	pages = {449-462},
	year = {2009},
	url = {https://doi.org/10.1016/j.ijindorg.2008.11.005}
}

@article{GMS_2017,
	title = {Contracting over the disclosure of scientific knowledge: Intellectual property and academic publication},
	author = {Joshua S. Gans and Fiona E. Murray and Scott Stern},
	journal = {Research Policy},
	volume = {46},
	number = {4},
	pages = {820-835},
	year = {2017},
	url = {https://doi.org/10.1016/j.respol.2017.02.005}
}

@article{O_2015,
	title = {Promises and Perils of Pre-analysis Plans},
	author = {Olken, Benjamin A.},
	journal = {Journal of Economic Perspectives},
	volume = {29},
	number = {3},
	pages = {61–80},
	year = {2015},
	url = {https://doi.org/10.1257/jep.29.3.61}
}

@article{BCH_2020,
	title = {Methods Matter: p-Hacking and Publication Bias in Causal Analysis in Economics},
	author = {Brodeur, Abel and Cook, Nikolai and Heyes, Anthony},
	journal = {American Economic Review},
	volume = {110},
	number = {11},
	year = {2020},
	pages = {3634–60},
	url = {https://doi.org/10.1257/aer.20190687}
}

@article{GM_2008a,
	title = {Do Statistical Reporting Standards Affect What Is Published? Publication Bias in Two Leading Political Science Journals},
	author = {Alan S. Gerber and Neil Malhotra},
	journal = {Quarterly Journal of Political Science},
	volume = {3},
	number = {3},
	pages = {313-326},
	year = {2008a},
	url = {http://dx.doi.org/10.1561/100.00008024},
}

@article{GM_2008b,
	title ={Publication Bias in Empirical Sociological Research: Do Arbitrary Significance Levels Distort Published Results?},
	author = {Alan S. Gerber and Neil Malhotra},
	journal = {Sociological Methods \& Research},
	volume = {37},
	number = {1},
	pages = {3-30},
	year = {2008b},
	url = {https://doi.org/10.1257/10.1177/0049124108318973}
}

@article{BCHH_2024,
	title = {Do Preregistration and Preanalysis Plans Reduce p-Hacking and Publication Bias? Evidence from 15,992 Test Statistics and Suggestions for Improvement},
	author = {Brodeur, Abel and Cook, Nikolai M. and Hartley, Jonathan S. and Heyes, Anthony},
	journal = {Journal of Political Economy Microeconomics},
	volume = {2},
	number = {3},
	pages = {527-561},
	year = {2024},
	url = {https://doi.org/10.1086/730455}
}

@article{DJ_2024,
  title={A Framework for Evaluating Reproducibility and Replicability in Economics},
  author={Dreber, Anna and Johannesson, Magnus},
  journal={Economic Inquiry},
	volume = {},
	number = {},
	pages = {},
	year = {2024},
	url = {https://doi.org/10.1111/ecin.13244}
}

@article{BCKU_2024,
  title={Incentives and the Replication Crisis in Social Sciences: A Critical Review of Open Science Practices},
  author={Balafoutas, Loukas and Celse, Jeremy and Karakostas, Alexandros and Umashev, Nicholas},
  journal={Journal of Behavioral and Experimental Economics},
  pages={102327},
	volume = {114},
	number = {},
	pages = {},
	year = {2024},
	url = {https://doi.org/10.1016/j.socec.2024.102327}
}